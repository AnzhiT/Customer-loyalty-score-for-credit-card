{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA is not applicable since DV is numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + Random Forest/Boosting/Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues (variance explained) for each principal component\n",
      "PC 1: 20.459\n",
      "PC 2: 16.236\n",
      "PC 3: 12.479\n",
      "PC 4: 9.037\n",
      "PC 5: 6.481\n",
      "PC 6: 5.860\n",
      "PC 7: 4.840\n",
      "PC 8: 4.213\n",
      "PC 9: 4.026\n",
      "PC 10: 3.993\n",
      "PC 11: 3.322\n",
      "PC 12: 3.228\n",
      "PC 13: 3.143\n",
      "PC 14: 2.974\n",
      "PC 15: 2.941\n",
      "PC 16: 2.891\n",
      "PC 17: 2.745\n",
      "PC 18: 2.671\n",
      "PC 19: 2.486\n",
      "PC 20: 2.069\n",
      "PC 21: 1.814\n",
      "PC 22: 1.742\n",
      "PC 23: 1.513\n",
      "PC 24: 1.499\n",
      "PC 25: 1.455\n",
      "PC 26: 1.440\n",
      "PC 27: 1.339\n",
      "PC 28: 1.256\n",
      "PC 29: 1.242\n",
      "PC 30: 1.203\n",
      "PC 31: 1.141\n",
      "PC 32: 1.067\n",
      "PC 33: 1.034\n",
      "PC 34: 1.003\n",
      "PC 35: 0.976\n",
      "PC 36: 0.943\n",
      "PC 37: 0.897\n",
      "PC 38: 0.844\n",
      "PC 39: 0.822\n",
      "PC 40: 0.808\n",
      "PC 41: 0.747\n",
      "PC 42: 0.736\n",
      "PC 43: 0.675\n",
      "PC 44: 0.621\n",
      "PC 45: 0.597\n",
      "PC 46: 0.576\n",
      "PC 47: 0.555\n",
      "PC 48: 0.501\n",
      "PC 49: 0.475\n",
      "PC 50: 0.462\n",
      "PC 51: 0.427\n",
      "PC 52: 0.385\n",
      "PC 53: 0.382\n",
      "PC 54: 0.377\n",
      "PC 55: 0.357\n",
      "PC 56: 0.335\n",
      "PC 57: 0.329\n",
      "PC 58: 0.324\n",
      "PC 59: 0.317\n",
      "PC 60: 0.305\n",
      "PC 61: 0.299\n",
      "PC 62: 0.289\n",
      "PC 63: 0.283\n",
      "PC 64: 0.270\n",
      "PC 65: 0.268\n",
      "PC 66: 0.262\n",
      "PC 67: 0.253\n",
      "PC 68: 0.215\n",
      "PC 69: 0.204\n",
      "PC 70: 0.196\n",
      "PC 71: 0.193\n",
      "PC 72: 0.173\n",
      "PC 73: 0.170\n",
      "PC 74: 0.162\n",
      "PC 75: 0.159\n",
      "PC 76: 0.146\n",
      "PC 77: 0.140\n",
      "PC 78: 0.133\n",
      "PC 79: 0.126\n",
      "PC 80: 0.120\n",
      "PC 81: 0.117\n",
      "PC 82: 0.112\n",
      "PC 83: 0.111\n",
      "PC 84: 0.104\n",
      "PC 85: 0.103\n",
      "PC 86: 0.098\n",
      "PC 87: 0.094\n",
      "PC 88: 0.092\n",
      "PC 89: 0.090\n",
      "PC 90: 0.085\n",
      "PC 91: 0.080\n",
      "PC 92: 0.074\n",
      "PC 93: 0.069\n",
      "PC 94: 0.064\n",
      "PC 95: 0.063\n",
      "PC 96: 0.062\n",
      "PC 97: 0.056\n",
      "PC 98: 0.051\n",
      "PC 99: 0.050\n",
      "PC 100: 0.048\n",
      "PC 101: 0.048\n",
      "PC 102: 0.045\n",
      "PC 103: 0.044\n",
      "PC 104: 0.042\n",
      "PC 105: 0.038\n",
      "PC 106: 0.033\n",
      "PC 107: 0.033\n",
      "PC 108: 0.032\n",
      "PC 109: 0.030\n",
      "PC 110: 0.028\n",
      "PC 111: 0.026\n",
      "PC 112: 0.024\n",
      "PC 113: 0.023\n",
      "PC 114: 0.022\n",
      "PC 115: 0.020\n",
      "PC 116: 0.018\n",
      "PC 117: 0.018\n",
      "PC 118: 0.018\n",
      "PC 119: 0.017\n",
      "PC 120: 0.016\n",
      "PC 121: 0.014\n",
      "PC 122: 0.013\n",
      "PC 123: 0.013\n",
      "PC 124: 0.012\n",
      "PC 125: 0.011\n",
      "PC 126: 0.011\n",
      "PC 127: 0.010\n",
      "PC 128: 0.007\n",
      "PC 129: 0.006\n",
      "PC 130: 0.004\n",
      "PC 131: 0.004\n",
      "PC 132: 0.004\n",
      "PC 133: 0.003\n",
      "PC 134: 0.003\n",
      "PC 135: 0.003\n",
      "PC 136: 0.002\n",
      "PC 137: 0.001\n",
      "PC 138: 0.001\n",
      "PC 139: 0.001\n",
      "PC 140: 0.000\n",
      "PC 141: 0.000\n",
      "PC 142: 0.000\n",
      "PC 143: 0.000\n",
      "PC 144: 0.000\n",
      "PC 145: 0.000\n",
      "PC 146: 0.000\n",
      "PC 147: 0.000\n",
      "PC 148: 0.000\n",
      "PC 149: 0.000\n",
      "PC 150: 0.000\n",
      "PC 151: 0.000\n",
      "PC 152: 0.000\n",
      "PC 153: 0.000\n",
      "PC 154: 0.000\n",
      "PC 155: 0.000\n",
      "PC 156: 0.000\n",
      "PC 157: 0.000\n",
      "% variance explained by PCA for the standardized X matrix\n",
      "[0.13 0.1  0.08 0.06 0.04 0.04 0.03 0.03 0.03 0.03 0.02 0.02 0.02 0.02\n",
      " 0.02 0.02 0.02 0.02 0.02 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " 0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()  \n",
    "X_train = sc.fit_transform(X_train)  \n",
    "X_test = sc.transform(X_test) \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA() # create a PCA object\n",
    "tr_pca = pca.fit(X_train)\n",
    "tr_eigenvalues = tr_pca.explained_variance_\n",
    "print('Eigenvalues (variance explained) for each principal component')\n",
    "for idx, eigenvalue in enumerate(tr_eigenvalues):\n",
    "    print('PC {}: {:.3f}'.format(idx + 1, eigenvalue))\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "with np.printoptions(precision=2):\n",
    "    print('% variance explained by PCA for the standardized X matrix')\n",
    "    print(tr_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 PC + RF\n",
    "pca = PCA(n_components=1)  \n",
    "X_train = pca.fit_transform(X_train)  \n",
    "X_test = pca.transform(X_test)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=1000, random_state=0)  \n",
    "rfr.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = rfr.predict(X_test)  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_rfr = mean_squared_error(y_test,y_pred)\n",
    "print(np.sqrt(error_rfr))# 4.64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error_rfr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-66c359e8438e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0merror_pca_rfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_rfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# n_estimators=1000, rmse=4.055\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'error_rfr' is not defined"
     ]
    }
   ],
   "source": [
    "# 2 PC + RF\n",
    "#%%time\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()  \n",
    "#X_train = sc.fit_transform(X_train)  \n",
    "#X_test = sc.transform(X_test)\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#pca2 = PCA(n_components=2)  \n",
    "#X_train = pca2.fit_transform(X_train)  \n",
    "#X_test = pca2.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=0)  \n",
    "rfr.fit(X_train, y_train)\n",
    "#round(importance(fit), 2), If you notice that by increasing trees these top predictors don't really change position relative to each other, and the importance metrics seem to stay the same, then you might want to consider not using so many trees.\n",
    "y_pred = rfr.predict(X_test)  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_pca_rfr = mean_squared_error(y_test,y_pred)\n",
    "print(np.sqrt(error_rfr)) # n_estimators=1000, rmse=4.055; n=100, rmse = 4.072"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()  \n",
    "#X_train = sc.fit_transform(X_train)  \n",
    "#X_test = sc.transform(X_test)\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#pca2 = PCA(n_components=2)  \n",
    "#X_train = pca2.fit_transform(X_train)  \n",
    "#X_test = pca2.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bag=BaggingRegressor(n_estimators=100, max_samples=0.3)\n",
    "bag.fit(X_train,y_train)\n",
    "y_pred_bag = bag.predict(X_test)\n",
    "error_bag = mean_squared_error(y_test,y_pred_bag)\n",
    "print(np.sqrt(error_bag)) # 3.932187973353431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8395720715032855\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#sc = StandardScaler()  \n",
    "#X_train = sc.fit_transform(X_train)  \n",
    "#X_test = sc.transform(X_test)\n",
    "\n",
    "#from sklearn.decomposition import PCA\n",
    "#pca2 = PCA(n_components=2)  \n",
    "#X_train = pca2.fit_transform(X_train)  \n",
    "#X_test = pca2.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm=GradientBoostingRegressor(n_estimators=100)\n",
    "gbm.fit(X_train,y_train)\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "error_gbm = mean_squared_error(y_test,y_pred_gbm)\n",
    "print(np.sqrt(error_gbm)) # 3.8395720715032855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=0)  \n",
    "rfr.fit(X_train, y_train)\n",
    "y_pred = rfr.predict(X_test)  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_rfr = mean_squared_error(y_test,y_pred)\n",
    "print(np.sqrt(error_rfr))#3.73, Wall time: 44min 33s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7218590871260924\n",
      "Wall time: 19min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "bag=BaggingRegressor(n_estimators=100, max_samples=0.3)\n",
    "bag.fit(X_train,y_train)\n",
    "y_pred_bag = bag.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_bag = mean_squared_error(y_test,y_pred_bag)\n",
    "print(np.sqrt(error_bag)) #3.7218590871260924, Wall time: 19min 19s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.680877221352022\n",
      "Wall time: 4min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "#tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "#del tr['Unnamed: 0']\n",
    "#del tr['first_active_month']\n",
    "#del tr['card_id']\n",
    "#y=tr.target\n",
    "#del tr['target']\n",
    "#X=tr\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm=GradientBoostingRegressor(n_estimators=100)\n",
    "gbm.fit(X_train,y_train)\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_gbm = mean_squared_error(y_test,y_pred_gbm)\n",
    "print(np.sqrt(error_gbm)) #3.680877221352022, Wall time: 4min 27s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN 5-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.153943098867342\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "\n",
    "#tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "#del tr['Unnamed: 0']\n",
    "#del tr['first_active_month']\n",
    "#del tr['card_id']\n",
    "#y=tr.target\n",
    "#del tr['target']\n",
    "#X=tr\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_knn=mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(np.sqrt(error_knn)) #4.15, Wall time: 50.1 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m     \"\"\"\n\u001b[0;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr_error = mean_squared_error(y_test,y_pred)\n",
    "print(np.sqrt(lr_error)) #3.7625753133561637"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.840567609904695\n"
     ]
    }
   ],
   "source": [
    "pca2 = PCA(n_components=2)  \n",
    "X_train = pca2.fit_transform(X_train)  \n",
    "X_test = pca2.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr_error = mean_squared_error(y_test,y_pred)\n",
    "print(np.sqrt(lr_error)) #3.840567609904695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.796012598440836\n"
     ]
    }
   ],
   "source": [
    "pca34 = PCA(n_components=34)  \n",
    "X_train = pca34.fit_transform(X_train)  \n",
    "X_test = pca34.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lr_error = mean_squared_error(y_test,y_pred)\n",
    "print(np.sqrt(lr_error))#3.796"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_lr = Lasso(alpha=0.01)#alpha=lambda\n",
    "lasso_lr.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_lasso = mean_squared_error(y_test,y_pred_lasso)\n",
    "print(np.sqrt(error_lasso)) ##3.786704893199252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8405701104956185\n"
     ]
    }
   ],
   "source": [
    "pca2 = PCA(n_components=2)  \n",
    "X_train = pca2.fit_transform(X_train)  \n",
    "X_test = pca2.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_lr = Lasso(alpha=0.01)#alpha=lambda\n",
    "lasso_lr.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_lasso = mean_squared_error(y_test,y_pred_lasso)\n",
    "print(np.sqrt(error_lasso)) ##3.8405701104956185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7962918322956325\n"
     ]
    }
   ],
   "source": [
    "pca34 = PCA(n_components=34)  \n",
    "X_train = pca34.fit_transform(X_train)  \n",
    "X_test = pca34.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_lr = Lasso(alpha=0.01)#alpha=lambda\n",
    "lasso_lr.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_lasso = mean_squared_error(y_test,y_pred_lasso)\n",
    "print(np.sqrt(error_lasso)) ##3.796"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7676191448388283\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) \n",
    "\n",
    "tr = pd.read_csv('D:/MSMA/DataScience/Elo/train_clean.csv')\n",
    "del tr['Unnamed: 0']\n",
    "del tr['first_active_month']\n",
    "del tr['card_id']\n",
    "y=tr.target\n",
    "del tr['target']\n",
    "X=tr\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "Ridge_lr = Ridge(alpha=0.9)#alpha=lambda\n",
    "Ridge_lr.fit(X_train, y_train)\n",
    "y_pred_Ridge = Ridge_lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_Ridge = mean_squared_error(y_test,y_pred_Ridge)\n",
    "print(np.sqrt(error_Ridge)) ##3.7676191448388283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8405676097549493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "Ridge_lr = Ridge(alpha=0.9)#alpha=lambda\n",
    "Ridge_lr.fit(X_train, y_train)\n",
    "y_pred_Ridge = Ridge_lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_Ridge = mean_squared_error(y_test,y_pred_Ridge)\n",
    "print(np.sqrt(error_Ridge)) ##3.8405676097549493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7960126060231243\n"
     ]
    }
   ],
   "source": [
    "pca34 = PCA(n_components=34)  \n",
    "X_train = pca34.fit_transform(X_train)  \n",
    "X_test = pca34.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "Ridge_lr = Ridge(alpha=0.9)#alpha=lambda\n",
    "Ridge_lr.fit(X_train, y_train)\n",
    "y_pred_Ridge = Ridge_lr.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "error_Ridge = mean_squared_error(y_test,y_pred_Ridge)\n",
    "print(np.sqrt(error_Ridge)) ##3.796"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
